{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_xai import ChatXAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_documents(pdf_folder):\n",
    "    \"\"\"\n",
    "    Loads all PDF documents from the specified folder using PDFPlumberLoader.\n",
    "    Returns a list of document objects.\n",
    "    \"\"\"\n",
    "    all_docs = []\n",
    "    if not os.path.exists(pdf_folder):\n",
    "        print(f\"PDF folder '{pdf_folder}' not found. Make sure your PDFs are in the folder.\")\n",
    "        return all_docs\n",
    "\n",
    "    for filename in os.listdir(pdf_folder):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder, filename)\n",
    "            print(\"Loading:\", pdf_path)\n",
    "            loader = PDFPlumberLoader(pdf_path)\n",
    "            all_docs.extend(loader.load())\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(documents, embedder, index_dir):\n",
    "    \"\"\"\n",
    "    Creates or loads a FAISS vector store from the provided documents using the specified embedder.\n",
    "    \"\"\"\n",
    "    if os.path.exists(index_dir):\n",
    "        vector = FAISS.load_local(index_dir, embedder, allow_dangerous_deserialization=True)\n",
    "        print(\"Loaded vector store from disk.\")\n",
    "    else:\n",
    "        # Split documents into chunks using SemanticChunker.\n",
    "        text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "        docs_chunks = text_splitter.split_documents(documents)\n",
    "        vector = FAISS.from_documents(docs_chunks, embedder)\n",
    "        vector.save_local(index_dir)\n",
    "        print(\"Created and saved new vector store.\")\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_llm_chain(llm):\n",
    "    \"\"\"\n",
    "    Creates an LLMChain using the provided LLM and a QA prompt.\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "1. Use the following pieces of context to answer the question at the end.\n",
    "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\n",
    "3. Keep the answer crisp and limited to 3-4 sentences.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "    QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt)\n",
    "    llm_chain = LLMChain(llm=llm, prompt=QA_CHAIN_PROMPT, verbose=True)\n",
    "    return llm_chain\n",
    "\n",
    "\n",
    "def build_combined_documents_chain(llm_chain):\n",
    "    \"\"\"\n",
    "    Creates a StuffDocumentsChain for combining retrieved documents using a custom document prompt.\n",
    "    \"\"\"\n",
    "    document_prompt = PromptTemplate(\n",
    "        input_variables=[\"page_content\", \"source\"],\n",
    "        template=\"Context:\\ncontent: {page_content}\\nsource: {source}\",\n",
    "    )\n",
    "    combined_chain = StuffDocumentsChain(\n",
    "        llm_chain=llm_chain,\n",
    "        document_variable_name=\"context\",\n",
    "        document_prompt=document_prompt,\n",
    "    )\n",
    "    return combined_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qa_chain(retriever, combined_documents_chain):\n",
    "    \"\"\"\n",
    "    Builds and returns a RetrievalQA chain using the provided retriever and combined documents chain.\n",
    "    \"\"\"\n",
    "    qa_chain = RetrievalQA(\n",
    "        combine_documents_chain=combined_documents_chain,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chain():\n",
    "    \"\"\"\n",
    "    Initializes the full RetrievalQA chain by:\n",
    "      1. Loading PDF documents from 'static/uploads'.\n",
    "      2. Creating or loading a FAISS vector store.\n",
    "      3. Building the LLM and associated chains.\n",
    "    Returns the initialized QA chain.\n",
    "    \"\"\"\n",
    "    pdf_folder = os.path.join(\"static\", \"uploads\")\n",
    "    all_docs = load_all_documents(pdf_folder)\n",
    "    if not all_docs:\n",
    "        print(\"No PDF documents loaded.\")\n",
    "        return None\n",
    "\n",
    "    index_dir = \"faiss_index\"\n",
    "    embedder = HuggingFaceEmbeddings()\n",
    "    vector = get_vector_store(all_docs, embedder, index_dir)\n",
    "    retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "    # Define the LLM \n",
    "    X_API=\"API KEY\"\n",
    "    llm= llm = ChatXAI(\n",
    "        model=\"grok-2-latest\",\n",
    "        temperature=0.01,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        api_key=X_API,\n",
    "        \n",
    "    )\n",
    "    llm_chain = build_llm_chain(llm)\n",
    "    combined_documents_chain = build_combined_documents_chain(llm_chain)\n",
    "    qa_chain = build_qa_chain(retriever, combined_documents_chain)\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(qa_chain, question):\n",
    "    \"\"\"\n",
    "    Runs the QA chain with the provided question.\n",
    "    Returns the answer and a relative URL for the source PDF (if available).\n",
    "    \"\"\"\n",
    "    response = qa_chain(question)\n",
    "    answer_text = response.get(\"result\", \"I don't know\")\n",
    "    pdf_url = None\n",
    "\n",
    "    if response.get(\"source_documents\") and len(response[\"source_documents\"]) > 0:\n",
    "        doc = response[\"source_documents\"][0]\n",
    "        metadata = doc.metadata\n",
    "        source_doc = metadata.get(\"source\", \"\")\n",
    "        page_num = metadata.get(\"page\", 0)\n",
    "        # Normalize path: replace backslashes with forward slashes.\n",
    "        normalized_source = source_doc.replace(\"\\\\\", \"/\")\n",
    "        # Remove any leading \"static/\" so we can build a relative URL.\n",
    "        if normalized_source.lower().startswith(\"static/\"):\n",
    "            normalized_source = normalized_source[len(\"static/\"):]\n",
    "        pdf_url = f\"/static/{normalized_source}#page={page_num+1}\"\n",
    "    return answer_text, pdf_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: static\\uploads\\CELEX_02006R1907-20231201_EN_TXT-Registration, Evaluation, Authorisation and Restriction of Chemicals (REACH).pdf\n",
      "Loading: static\\uploads\\CELEX_31994L0062_EN_TXT-packaging and packaging waste.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19556\\2307225981.py:16: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedder = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vector store from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19556\\3741286893.py:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=QA_CHAIN_PROMPT, verbose=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19556\\3741286893.py:28: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  combined_chain = StuffDocumentsChain(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19556\\1481620643.py:5: LangChainDeprecationWarning: This class is deprecated. Use the `create_retrieval_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n",
      "  qa_chain = RetrievalQA(\n"
     ]
    }
   ],
   "source": [
    "qa_chain = initialize_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = \" ESSENTAIL REQUIREMENTS ON THE COMPOSITION AND THE REUSABLE AND RECOVERABLE, INCLUDINGRECYCLABLE,NATUREOFPACKAGING\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19556\\409160770.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "1. Use the following pieces of context to answer the question at the end.\n",
      "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\n",
      "3. Keep the answer crisp and limited to 3-4 sentences.\n",
      "\n",
      "Context: Context:\n",
      "content: 12. 94 Official Journal of the European Communities No L 365/19\n",
      "ANNEX II\n",
      "ESSENTAIL REQUIREMENTS ON THE COMPOSITION AND THE REUSABLE AND\n",
      "RECOVERABLE, INCLUDING RECYCLABLE, NATURE OF PACKAGING\n",
      "1. Requirements specific to the manufacturing and composition of packaging\n",
      "— Packaging shall be so manufactured that the packaging volume and weight be limited to the\n",
      "minimum adequate amount to maintain the necessary level ofsafety, hygiene and acceptance for the\n",
      "packed product and for the consumer. — Packaging shall be designed, produced and commercialized in such a way as to permit its reuse or\n",
      "recovery, including recycling, and to minimize its impact on the environment when packaging waste\n",
      "or residues from packaging waste management operations are disposed of. — Packaging shall be so manufactured that the presence of noxious and other hazardous substances\n",
      "and materials as constituents of the packaging material or of any of the packaging components is\n",
      "minimized with regard to their presence in emissions, ash or leachate when packaging or residues\n",
      "from management operations or packaging waste are incinerated or landfilled. 2. Requirements specific to the reusable nature ofpackaging\n",
      "The following requirements must be simultaneously satisfied:\n",
      "— the physical properties and characteristics of the packaging shall enable a number of trips or\n",
      "rotations in normally predictable conditions of use,\n",
      "— possiblity of processing the used packaging in order to meet health and safety requirements for the\n",
      "workforce,\n",
      "— fulfil the requirements specific to recoverable packaging when the packaging is no longer reused and\n",
      "thus becomes waste. 3. Requirements specific to the recoverable nature of packaging\n",
      "(a) Packaging recoverable in the form ofmaterial recycling\n",
      "Packaging must be manufactured in such a way as to enable the recycling ofa certain percentage by\n",
      "weight of the materials used into the manufacture of marketable products, in compliance with\n",
      "current standards in the Community. The establishment of this percentage may vary, depending on\n",
      "the type of material of which the packaging is composed. (b) Packaging recoverable in the form ofenergy recovery\n",
      "Packagingwasteprocessedforthepurpose ofenergyrecovery shall have a minimum inferiorcalorific\n",
      "value to allow optimization of energy recovery. (c) Packaging recoverable in the form ofcomposting\n",
      "Packaging waste processed for the purpose of composting shall be of such a biodegradable nature\n",
      "that it should not hinder the separate collection aiid the composting process or activity into which it\n",
      "is introduced. (d) Biodegradablepackaging\n",
      "Biodegradable packaging waste shall be of such a nature that it is capable of undergoing physical,\n",
      "chemical, thermal or biological decomposition such that most of the finished compost ultimately\n",
      "decomposes into carbon dioxide, biomass and water. \n",
      "source: static\\uploads\\CELEX_31994L0062_EN_TXT-packaging and packaging waste.pdf\n",
      "\n",
      "Question:  ESSENTAIL REQUIREMENTS ON THE COMPOSITION AND THE REUSABLE AND RECOVERABLE, INCLUDINGRECYCLABLE,NATUREOFPACKAGING\n",
      "\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer, pdf_url = get_response(qa_chain, sample_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  ESSENTAIL REQUIREMENTS ON THE COMPOSITION AND THE REUSABLE AND RECOVERABLE, INCLUDINGRECYCLABLE,NATUREOFPACKAGING\n",
      "Answer: The essential requirements for packaging composition and its reusable and recoverable nature, as outlined in the Official Journal of the European Communities, focus on minimizing the environmental impact of packaging. Packaging must be manufactured to limit its volume and weight to the minimum necessary while ensuring safety, hygiene, and consumer acceptance. It should be designed for reuse or recovery, including recycling, and minimize the presence of hazardous substances. Additionally, packaging must meet specific criteria for being reusable and recoverable, such as enabling multiple uses, being processable for health and safety, and being recyclable or suitable for energy recovery or composting.\n",
      "PDF URL: /static/uploads/CELEX_31994L0062_EN_TXT-packaging and packaging waste.pdf#page=10\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\", sample_question)\n",
    "print(\"Answer:\", answer)\n",
    "print(\"PDF URL:\", pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
